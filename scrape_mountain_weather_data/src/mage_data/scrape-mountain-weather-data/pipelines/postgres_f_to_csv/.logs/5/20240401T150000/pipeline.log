2024-04-01T15:00:00 {"cpu": 0.21728515625, "cpu_total": 16, "cpu_usage": 0.013580322265625, "memory": 2658.0, "memory_total": 9698.0, "memory_usage": 0.2740771293050113, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983600.959938, "uuid": "0ed3af0353524211a7e901722b73db27"}
2024-04-01T15:00:01 {"block_run_id": 770, "block_uuid": "load_final_postgres", "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Execute PipelineRun 283, BlockRun 770: pipeline postgres_f_to_csv block load_final_postgres", "timestamp": 1711983601.864077, "uuid": "ad1c6e7f4a5c4128b3a03dc259649968"}
2024-04-01T15:00:02 {"cpu": 0.21728515625, "cpu_total": 16, "cpu_usage": 0.013580322265625, "memory": 2840.0, "memory_total": 9698.0, "memory_usage": 0.2928438853371829, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983602.128028, "uuid": "9af82597c3ae450093c037594a497d5c"}
2024-04-01T15:00:10 {"cpu": 0.21435546875, "cpu_total": 16, "cpu_usage": 0.013397216796875, "memory": 2938.0, "memory_total": 9698.0, "memory_usage": 0.30294906166219837, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983610.989651, "uuid": "355b4e74607247b0af90580cf251acef"}
2024-04-01T15:00:20 {"cpu": 0.21142578125, "cpu_total": 16, "cpu_usage": 0.013214111328125, "memory": 2997.0, "memory_total": 9698.0, "memory_usage": 0.30903279026603425, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983620.962804, "uuid": "94d2b2ff78324cd3975116ed73df596a"}
2024-04-01T15:00:30 {"cpu": 0.20849609375, "cpu_total": 16, "cpu_usage": 0.013031005859375, "memory": 3000.0, "memory_total": 9698.0, "memory_usage": 0.30934213239843267, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983630.774176, "uuid": "e2639634ecf642b78379dff11dc8a6c7"}
2024-04-01T15:00:40 {"cpu": 0.20556640625, "cpu_total": 16, "cpu_usage": 0.012847900390625, "memory": 3001.0, "memory_total": 9698.0, "memory_usage": 0.3094452464425655, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983640.616857, "uuid": "ac463d3135d340fbac5408b7b5127758"}
2024-04-01T15:00:51 {"cpu": 0.20849609375, "cpu_total": 16, "cpu_usage": 0.013031005859375, "memory": 3001.0, "memory_total": 9698.0, "memory_usage": 0.3094452464425655, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983651.425219, "uuid": "5c20db63cc3d4d429338e38b0662d48f"}
2024-04-01T15:01:01 {"cpu": 0.20556640625, "cpu_total": 16, "cpu_usage": 0.012847900390625, "memory": 3006.0, "memory_total": 9698.0, "memory_usage": 0.30996081666322955, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983661.264315, "uuid": "13ff6d9382a14122ba07a62feced464c"}
2024-04-01T15:01:03 {"block_run_id": 770, "block_uuid": "load_final_postgres", "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "EXCEPTION", "message": "BlockRun 770 (block_uuid: load_final_postgres) failed.", "timestamp": 1711983663.205059, "uuid": "ccb923c599ae4f5eae8716813eadbf40", "error": ["Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 2018, in execute\n    cur.execute(*args, **kwargs)\npsycopg2.errors.UndefinedTable: relation \"forecast_data.scraped_forecasts_final\" does not exist\nLINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final\n                          ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 605, in execute\n    result = __execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 54, in retry_func\n    raise e\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 38, in retry_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 578, in __execute_with_retry\n    return self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 1052, in _execute\n    result = self.block.execute_sync(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1285, in execute_sync\n    raise err\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1194, in execute_sync\n    output = self.execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1509, in execute_block\n    outputs = self._execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1665, in _execute_block\n    outputs = self.execute_block_function(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1704, in execute_block_function\n    output = block_function_updated(*input_vars, **global_vars)\n  File \"<string>\", line 24, in load_data_from_postgres\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/io/sql.py\", line 207, in load\n    return read_sql(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 564, in read_sql\n    return pandas_sql.read_query(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 2078, in read_query\n    cursor = self.execute(*args)\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 2030, in execute\n    raise ex from exc\npandas.errors.DatabaseError: Execution failed on sql '\nWITH subquery AS (\n    SELECT * FROM forecast_data.scraped_forecasts_final\n)\n\nSELECT *\nFROM subquery\nLIMIT 10000000\n': relation \"forecast_data.scraped_forecasts_final\" does not exist\nLINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final\n                          ^\n\n"], "error_stack": [["  File \"/usr/local/bin/mage\", line 8, in <module>\n    sys.exit(app())\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/cli/main.py\", line 163, in start\n    start_server(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/server.py\", line 659, in start_server\n    scheduler_manager.start_scheduler()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 87, in start_scheduler\n    proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 50, in run_scheduler\n    LoopTimeTrigger().start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/loop_time_trigger.py\", line 14, in start\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/time_trigger.py\", line 11, in run\n    schedule_all()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1552, in schedule_all\n    PipelineScheduler(r).start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 182, in start\n    self.schedule()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 319, in schedule\n    self.__schedule_blocks(block_runs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 581, in __schedule_blocks\n    job_manager.add_job(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/job_manager.py\", line 27, in add_job\n    self.queue.enqueue(job_id, target, *args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 107, in enqueue\n    self.start_worker_pool()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 173, in start_worker_pool\n    self.worker_pool_proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 275, in poll_job_and_execute\n    worker.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/newrelic/api/background_task.py\", line 117, in wrapper\n    return wrapped(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 240, in run\n    start_session_and_run(args[1], *args[2], **args[3])\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1105, in run_block\n    return ExecutorFactory.get_block_executor(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 621, in execute\n    on_failure(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 415, in on_block_failure\n    self.logger.exception(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 30, in exception\n    self.__send_message('exception', message, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 59, in __send_message\n    data['error_stack'] = traceback.format_stack(),\n"]], "error_stacktrace": ["Execution failed on sql '\nWITH subquery AS (\n    SELECT * FROM forecast_data.scraped_forecasts_final\n)\n\nSELECT *\nFROM subquery\nLIMIT 10000000\n': relation \"forecast_data.scraped_forecasts_final\" does not exist\nLINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final\n                          ^\n"]}
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in execute
    cur.execute(*args, **kwargs)
psycopg2.errors.UndefinedTable: relation "forecast_data.scraped_forecasts_final" does not exist
LINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final
                          ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 605, in execute
    result = __execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 54, in retry_func
    raise e
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 38, in retry_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 578, in __execute_with_retry
    return self._execute(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 1052, in _execute
    result = self.block.execute_sync(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1285, in execute_sync
    raise err
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1194, in execute_sync
    output = self.execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1509, in execute_block
    outputs = self._execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1665, in _execute_block
    outputs = self.execute_block_function(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1704, in execute_block_function
    output = block_function_updated(*input_vars, **global_vars)
  File "<string>", line 24, in load_data_from_postgres
  File "/usr/local/lib/python3.10/site-packages/mage_ai/io/sql.py", line 207, in load
    return read_sql(
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 564, in read_sql
    return pandas_sql.read_query(
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 2078, in read_query
    cursor = self.execute(*args)
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 2030, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql '
WITH subquery AS (
    SELECT * FROM forecast_data.scraped_forecasts_final
)

SELECT *
FROM subquery
LIMIT 10000000
': relation "forecast_data.scraped_forecasts_final" does not exist
LINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final
                          ^

2024-04-01T15:01:11 {"cpu": 0.20263671875, "cpu_total": 16, "cpu_usage": 0.012664794921875, "memory": 2688.0, "memory_total": 9698.0, "memory_usage": 0.27717055062899565, "pipeline_run_id": 283, "pipeline_schedule_id": 5, "pipeline_uuid": "postgres_f_to_csv", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_f_to_csv for run 283 in schedule 5 is alive.", "timestamp": 1711983671.069392, "uuid": "2dfb90fab4e54cb09f2117e645216cb5"}
