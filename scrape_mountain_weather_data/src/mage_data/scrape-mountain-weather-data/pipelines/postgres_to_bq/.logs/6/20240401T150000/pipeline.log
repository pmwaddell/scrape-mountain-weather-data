2024-04-01T15:00:01 {"cpu": 0.21728515625, "cpu_total": 16, "cpu_usage": 0.013580322265625, "memory": 2693.0, "memory_total": 9698.0, "memory_usage": 0.2776861208496597, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983601.803015, "uuid": "55c90e2afe33459e9aec85fff43f3210"}
2024-04-01T15:00:02 {"cpu": 0.21728515625, "cpu_total": 16, "cpu_usage": 0.013580322265625, "memory": 2842.0, "memory_total": 9698.0, "memory_usage": 0.29305011342544857, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983602.344919, "uuid": "ae73637fff6e4103812c30cacf813999"}
2024-04-01T15:00:02 {"block_run_id": 774, "block_uuid": "load_final_postgres", "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Execute PipelineRun 285, BlockRun 774: pipeline postgres_to_bq block load_final_postgres", "timestamp": 1711983602.842857, "uuid": "865bff66d95646e7a04b8d39a75c1f69"}
2024-04-01T15:00:11 {"cpu": 0.21435546875, "cpu_total": 16, "cpu_usage": 0.013397216796875, "memory": 2939.0, "memory_total": 9698.0, "memory_usage": 0.3030521757063312, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983611.203406, "uuid": "8858b133c9384dfbb3d2701a5703c994"}
2024-04-01T15:00:21 {"cpu": 0.21142578125, "cpu_total": 16, "cpu_usage": 0.013214111328125, "memory": 2997.0, "memory_total": 9698.0, "memory_usage": 0.30903279026603425, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983621.17074, "uuid": "bb2990ae71f84319b94b65518b438609"}
2024-04-01T15:00:30 {"cpu": 0.20849609375, "cpu_total": 16, "cpu_usage": 0.013031005859375, "memory": 3001.0, "memory_total": 9698.0, "memory_usage": 0.3094452464425655, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983630.987751, "uuid": "5d7dbd9a27bd46f698db96741448cd1a"}
2024-04-01T15:00:40 {"cpu": 0.20556640625, "cpu_total": 16, "cpu_usage": 0.012847900390625, "memory": 2999.0, "memory_total": 9698.0, "memory_usage": 0.30923901835429984, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983640.818158, "uuid": "11ee93ee0ffc4217a966f1c2ce9865bb"}
2024-04-01T15:00:51 {"cpu": 0.20849609375, "cpu_total": 16, "cpu_usage": 0.013031005859375, "memory": 3001.0, "memory_total": 9698.0, "memory_usage": 0.3094452464425655, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983651.627483, "uuid": "432b0cb7443944d0b4248b73390b7122"}
2024-04-01T15:01:01 {"cpu": 0.20556640625, "cpu_total": 16, "cpu_usage": 0.012847900390625, "memory": 3006.0, "memory_total": 9698.0, "memory_usage": 0.30996081666322955, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983661.470407, "uuid": "4752dc0055414c53a1108a3181200f5c"}
2024-04-01T15:01:03 {"block_run_id": 774, "block_uuid": "load_final_postgres", "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "EXCEPTION", "message": "BlockRun 774 (block_uuid: load_final_postgres) failed.", "timestamp": 1711983663.141162, "uuid": "c93acdcaaba8467bb438f8243557e121", "error": ["Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 2018, in execute\n    cur.execute(*args, **kwargs)\npsycopg2.errors.UndefinedTable: relation \"forecast_data.scraped_forecasts_final\" does not exist\nLINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final\n                          ^\n\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 605, in execute\n    result = __execute_with_retry()\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 54, in retry_func\n    raise e\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py\", line 38, in retry_func\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 578, in __execute_with_retry\n    return self._execute(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 1052, in _execute\n    result = self.block.execute_sync(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1285, in execute_sync\n    raise err\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1194, in execute_sync\n    output = self.execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1509, in execute_block\n    outputs = self._execute_block(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1665, in _execute_block\n    outputs = self.execute_block_function(\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py\", line 1704, in execute_block_function\n    output = block_function_updated(*input_vars, **global_vars)\n  File \"<string>\", line 24, in load_data_from_postgres\n  File \"/usr/local/lib/python3.10/site-packages/mage_ai/io/sql.py\", line 207, in load\n    return read_sql(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 564, in read_sql\n    return pandas_sql.read_query(\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 2078, in read_query\n    cursor = self.execute(*args)\n  File \"/usr/local/lib/python3.10/site-packages/pandas/io/sql.py\", line 2030, in execute\n    raise ex from exc\npandas.errors.DatabaseError: Execution failed on sql '\nWITH subquery AS (\n    SELECT * FROM forecast_data.scraped_forecasts_final\n)\n\nSELECT *\nFROM subquery\nLIMIT 10000000\n': relation \"forecast_data.scraped_forecasts_final\" does not exist\nLINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final\n                          ^\n\n"], "error_stack": [["  File \"/usr/local/bin/mage\", line 8, in <module>\n    sys.exit(app())\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 311, in __call__\n    return get_command(self)(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n    return self.main(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 778, in main\n    return _main(\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/core.py\", line 216, in _main\n    rv = self.invoke(ctx)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n    return _process_result(sub_ctx.command.invoke(sub_ctx))\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n", "  File \"/usr/local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n    return __callback(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/typer/main.py\", line 683, in wrapper\n    return callback(**use_params)  # type: ignore\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/cli/main.py\", line 163, in start\n    start_server(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/server.py\", line 659, in start_server\n    scheduler_manager.start_scheduler()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 87, in start_scheduler\n    proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/server/scheduler_manager.py\", line 50, in run_scheduler\n    LoopTimeTrigger().start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/loop_time_trigger.py\", line 14, in start\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/triggers/time_trigger.py\", line 11, in run\n    schedule_all()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1552, in schedule_all\n    PipelineScheduler(r).start()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 182, in start\n    self.schedule()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 319, in schedule\n    self.__schedule_blocks(block_runs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 581, in __schedule_blocks\n    job_manager.add_job(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/job_manager.py\", line 27, in add_job\n    self.queue.enqueue(job_id, target, *args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 107, in enqueue\n    self.start_worker_pool()\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 173, in start_worker_pool\n    self.worker_pool_proc.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 108, in run\n    self._target(*self._args, **self._kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 275, in poll_job_and_execute\n    worker.start()\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 121, in start\n    self._popen = self._Popen(self)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 224, in _Popen\n    return _default_context.get_context().Process._Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/context.py\", line 281, in _Popen\n    return Popen(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 19, in __init__\n    self._launch(process_obj)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/popen_fork.py\", line 71, in _launch\n    code = process_obj._bootstrap(parent_sentinel=child_r)\n", "  File \"/usr/local/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n    self.run()\n", "  File \"/usr/local/lib/python3.10/site-packages/newrelic/api/background_task.py\", line 117, in wrapper\n    return wrapped(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/queue/process_queue.py\", line 240, in run\n    start_session_and_run(args[1], *args[2], **args[3])\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/process.py\", line 15, in start_session_and_run\n    results = target(*args)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 1105, in run_block\n    return ExecutorFactory.get_block_executor(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py\", line 621, in execute\n    on_failure(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/db/__init__.py\", line 149, in func_with_rollback\n    return func(*args, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/orchestration/pipeline_scheduler_original.py\", line 415, in on_block_failure\n    self.logger.exception(\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 30, in exception\n    self.__send_message('exception', message, **kwargs)\n", "  File \"/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/logging/logger.py\", line 59, in __send_message\n    data['error_stack'] = traceback.format_stack(),\n"]], "error_stacktrace": ["Execution failed on sql '\nWITH subquery AS (\n    SELECT * FROM forecast_data.scraped_forecasts_final\n)\n\nSELECT *\nFROM subquery\nLIMIT 10000000\n': relation \"forecast_data.scraped_forecasts_final\" does not exist\nLINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final\n                          ^\n"]}
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 2018, in execute
    cur.execute(*args, **kwargs)
psycopg2.errors.UndefinedTable: relation "forecast_data.scraped_forecasts_final" does not exist
LINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final
                          ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 605, in execute
    result = __execute_with_retry()
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 54, in retry_func
    raise e
  File "/usr/local/lib/python3.10/site-packages/mage_ai/shared/retry.py", line 38, in retry_func
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 578, in __execute_with_retry
    return self._execute(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/executors/block_executor.py", line 1052, in _execute
    result = self.block.execute_sync(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1285, in execute_sync
    raise err
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1194, in execute_sync
    output = self.execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1509, in execute_block
    outputs = self._execute_block(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1665, in _execute_block
    outputs = self.execute_block_function(
  File "/usr/local/lib/python3.10/site-packages/mage_ai/data_preparation/models/block/__init__.py", line 1704, in execute_block_function
    output = block_function_updated(*input_vars, **global_vars)
  File "<string>", line 24, in load_data_from_postgres
  File "/usr/local/lib/python3.10/site-packages/mage_ai/io/sql.py", line 207, in load
    return read_sql(
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 564, in read_sql
    return pandas_sql.read_query(
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 2078, in read_query
    cursor = self.execute(*args)
  File "/usr/local/lib/python3.10/site-packages/pandas/io/sql.py", line 2030, in execute
    raise ex from exc
pandas.errors.DatabaseError: Execution failed on sql '
WITH subquery AS (
    SELECT * FROM forecast_data.scraped_forecasts_final
)

SELECT *
FROM subquery
LIMIT 10000000
': relation "forecast_data.scraped_forecasts_final" does not exist
LINE 3:     SELECT * FROM forecast_data.scraped_forecasts_final
                          ^

2024-04-01T15:01:12 {"cpu": 0.20263671875, "cpu_total": 16, "cpu_usage": 0.012664794921875, "memory": 2690.0, "memory_total": 9698.0, "memory_usage": 0.2773767787172613, "pipeline_run_id": 285, "pipeline_schedule_id": 6, "pipeline_uuid": "postgres_to_bq", "hostname": "21e5326a3a0e", "level": "INFO", "message": "Pipeline postgres_to_bq for run 285 in schedule 6 is alive.", "timestamp": 1711983672.153174, "uuid": "1420614620634b4ab57e2c0a3ea64883"}
